{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.integrate as sp_int\n",
    "import scipy.sparse as sp_sp\n",
    "import scipy.sparse.linalg as sp_la\n",
    "import scipy.signal as sp_sgn\n",
    "import scipy.fft as sp_fft\n",
    "pi=np.pi\n",
    "# For graphic display in Jupyter Notebook\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining classes: here I made 3 classes, which are: Gaussian, Kernel, Kernel_Turing_model.\n",
    "# The three have a hierarchy of Gaussian < Kernel < Kernel_Turing_model,\n",
    "\n",
    "\n",
    "#\n",
    "# class Gaussian defines the Gaussian function needed to define the activator (A(x))\n",
    "# and inhibitor (I(x)). \n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "# Gaussian.amp (float) ... the amplitude of the Gaussian function (value of the peak)\n",
    "#\n",
    "# Gaussian.width (float) ... this was unclear in the original paper, as \"width\" of a Gaussian distribution is infinite...\n",
    "#                            here I assume that it is supposed to be the standard deviation which defines how \"fat\" the function will be.\n",
    "#\n",
    "# Gaussian.dist (float) ... the mean of the Gaussian function, in other words the distance from the origin.\n",
    "#\n",
    "#\n",
    "# Methods:\n",
    "#\n",
    "# Gaussian.func(x) ... returns the function values of the Gaussian\n",
    "# \n",
    "#   Input: x - a numpy array of any dimension.\n",
    "#\n",
    "#   Output: the Gaussian function values at x.\n",
    "#\n",
    "# (To be honest this class was not really necessary... but it makes nice organizastion!)\n",
    "#\n",
    "\n",
    "class Gaussian():\n",
    "  def __init__(self, _amp, _width, _dist):\n",
    "    self.amp = _amp\n",
    "    self.width = _width\n",
    "    self.dist = _dist\n",
    "\n",
    "  def func(self, x):\n",
    "    return self.amp/(2*pi)**0.5 * np.exp(-((x-self.dist)/self.width)**2/2)\n",
    "\n",
    "#\n",
    "# class Kernel is the kernel used for the convolution to calculate the stimulus.\n",
    "# It is defined with two Gaussian classes, one activator (positive) and one inhibitor (negative).\n",
    "# It is initialized from the (amp, width, dist) x 2 of the two Gaussian classes.\n",
    "# It has methods for calculating its integral value at [-inf, inf], performing Fourier transform, and visualization.\n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "# Kernel.A (class Gaussian) ... the activator Gaussian function A(x)\n",
    "#\n",
    "# Kernel.I (class Gaussian) ... the inhibitor Gaussian function I(x)\n",
    "#\n",
    "#\n",
    "# Methods:\n",
    "#\n",
    "# Kernel.func(x) ... returns Kernel(x)\n",
    "# \n",
    "#   Input: x - a numpy array of any dimension.\n",
    "#\n",
    "#   Output: the Kernel values at x. This is equal to Kernel(x) = A(x) + I(x) as written in the paper.\n",
    "#\n",
    "# Kernel.integral(N=1000) ... estimates the 2D integral of Kernel(x) in [-inf,inf] x [-inf,inf].\n",
    "#                             it is not possible to do an integral in infinite domain, so the result is an approximation\n",
    "#                             done in a domain large enough. It uses the trapezoid integral of scipy to integrate discretely.\n",
    "# \n",
    "#   Input: N - mesh size of the grid. No particular need to change this value as N=1000 is enough for accuracy.\n",
    "#\n",
    "#   Output: the value of the (estimated) integral of Kernel(x) \n",
    "#\n",
    "# Kernel.FFT() ... performs a fast fourier transform of Kernel(x) to show dominant frequencies.\n",
    "#                  It sets the output (yf) as well as the frequency (xf) which will be used in the summary plot.\n",
    "#\n",
    "#\n",
    "# Kernel.summary(x) ... returns the summary figure of the Kernel.\n",
    "#\n",
    "#   Input: x - the x-axis used for the plot. Only needed if the plot is drawn badly.\n",
    "#\n",
    "#   Output: a figure with the information below:\n",
    "#           - plot of Kernel(x)\n",
    "#           - FFT result of Kernel(x)\n",
    "#           - (estimated) integral value of Kernel(x) with x in R^2\n",
    "#\n",
    "\n",
    "class Kernel():\n",
    "  def __init__(self, _ampA, _ampI, _widthA, _widthI, _distA, _distI):\n",
    "    self.A = Gaussian(_ampA, _widthA, _distA)\n",
    "    self.I = Gaussian(_ampI, _widthI, _distI)\n",
    "\n",
    "  def func(self,x):\n",
    "    return self.A.func(x) + self.I.func(x)\n",
    "\n",
    "  def integral(self, N=1000):\n",
    "    end = np.max((12*self.A.width+self.A.dist,12*self.I.width+self.I.dist))\n",
    "    X, Y = np.meshgrid(np.linspace(0,end,N),np.linspace(0,end,N))\n",
    "    dx = end/(N-1)\n",
    "    dist = (X**2 + Y**2)**0.5\n",
    "    return 4*sp_int.trapezoid(sp_int.trapezoid(self.func(dist),dx=dx),dx=dx)\n",
    "\n",
    "  def FFT(self):\n",
    "    N = 10000\n",
    "    lims = [0,N]\n",
    "    x = np.linspace(lims[0],lims[1],N)\n",
    "    yf = sp_fft.rfft(self.func(x))\n",
    "    xf = sp_fft.rfftfreq(len(x))\n",
    "    self.xf = xf\n",
    "    self.yf = yf\n",
    "\n",
    "  def summary(self,x=np.linspace(0,20,1000)):\n",
    "    fig, ax = plt.subplots(1,2,figsize=(15,5))\n",
    "    fig.suptitle('Kernel Summary')\n",
    "    ax[0].fill_between(x,self.A.func(x),color='g',alpha=0.3,label=r'$A(x)$')\n",
    "    ax[0].fill_between(x,self.I.func(x),color='r',alpha=0.3,label=r'$I(x)$')\n",
    "    ax[0].plot(x,self.func(x),'k',label=r'$Kernel(x) = A(x) + I(x)$')\n",
    "    ax[0].set_xlabel(r'Distance from signaling source $x$')\n",
    "    ax[0].set_title('Kernel Shape (Integral value: {:.3f})'.format(self.integral()))\n",
    "    ax[0].grid()\n",
    "    ax[0].legend()\n",
    "    self.FFT()\n",
    "    ax[1].fill_between(self.xf,self.yf,color='k',alpha=0.8)\n",
    "    ax[1].set_xticks([0,self.xf[-1]])\n",
    "    ax[1].set_yticks([])\n",
    "    ax[1].set_xlim(left=0,right=self.xf[-1])\n",
    "    ax[1].set_xlabel('Frequencies')\n",
    "    ax[1].set_title('FFT Profile') \n",
    "\n",
    "#\n",
    "# class Kernel_Turing_model is the main model used to generate the Turing pattern.\n",
    "# To solve the ODE defined in the paper, we iterate with time increment dt to numerically approximate the values at the grid.\n",
    "#\n",
    "# Parameters:\n",
    "#\n",
    "# Kernel_Turing_model.Kernel (class Kernel) ... the Kernel function Kernel(x)\n",
    "#\n",
    "# Kernel_Turing_model.X\n",
    "# Kernel_Turing_model.Y ... x and y coordinates of each grid position. This can be generated from numpy function meshgrid().\n",
    "#\n",
    "# Kernel_Turing_model.dt ... the value of dt used to solve the ODE. Since our goal is to see the final steady state, it is not necessary to\n",
    "#                            set this value too small (unless the scheme becomes unstable).\n",
    "#\n",
    "# Kernel_Turing_model.t ... the current time. This value is updated when the method .update_grid() is run\n",
    "#\n",
    "# Kernel_Turing_model.grid ... u(t,x,y) stored as a 2D matrix. This is updated according to the ODE using .update_grid()\n",
    "#\n",
    "#\n",
    "# Methods:\n",
    "#\n",
    "# Kernel_Turing_model.stim() ... returns Stim(x,y) as explained in the paper. Uses 2D convolution (of scipy library) using periodic\n",
    "#                                boundary conditions. The distance from origin (sqrt(x**2 + y**2)) is passed on to the argument of Kernel.\n",
    "#                                Used in the method .update_grid() to calculate the value of u(t+dt,x,y) from u(t,x,y).\n",
    "#\n",
    "# Kernel_Turing_model.reset_grid() ... resets u(t,x,y) to u(0,x,y) with random samples from normal distribution. \n",
    "\n",
    "#\n",
    "# Kernel_Turing_model.update_grid(deg=0.1) ... calculates u(t+dt,x,y) from u(t,x,y) using explicit scheme. The governing ODE is taken from\n",
    "#                                              Equation (2) of the original paper. Since the value of \"deg\" was not specified in the paper,\n",
    "#                                              here I set the default value to 0.1 (which can be changed as an argument).\n",
    "#\n",
    "# Kernel_Turing_model.gridplot() ... plots the image of u(t,x,y). If t is large enough and the Kernel is appropriate, then we should\n",
    "#                                    observe a Turing pattern.\n",
    "#\n",
    "\n",
    "class Kernel_Turing_model():\n",
    "  def __init__(self, _Kernel, _X, _Y, _dt):\n",
    "    self.Kernel = _Kernel\n",
    "    self.X = _X\n",
    "    self.Y = _Y\n",
    "    self.dt = _dt\n",
    "    self.t = 0\n",
    "    self.grid = np.random.randn(X.shape[0],X.shape[1])\n",
    "\n",
    "  def stim(self):\n",
    "    dist = (self.X**2 + self.Y**2)**0.5\n",
    "    stim = sp_sgn.convolve2d(self.grid, self.Kernel.func(dist), mode='same', boundary='wrap')\n",
    "    return np.clip(stim,0,1000)\n",
    "  def reset_grid(self):\n",
    "    self.grid = np.random.randn(X.shape[0],X.shape[1])\n",
    "    self.t = 0\n",
    "\n",
    "  def update_grid(self, deg=0):\n",
    "    grid_new = self.grid + (self.stim() - deg*self.grid)*self.dt\n",
    "    self.grid = grid_new\n",
    "    self.t += self.dt\n",
    "\n",
    "  def gridplot(self, ax):\n",
    "    x = self.X[0,:]\n",
    "    y = self.Y[:,0]\n",
    "    ax.imshow(self.grid, cmap='gray', extent=(x[0],x[-1],y[0],y[-1]))\n",
    "    ax.set_title('Result at t = {:.3f}'.format(self.t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Here is an example code: First we define our Kernel by passing the amplitude, width, and distance values the two Gaussians\n",
    "# Keep in mind that the order of the arguments is (ampA, ampI, widthA, widthI, distA, distI)\n",
    "K = Kernel(20.267,-2.133,1.817,5.835,0,0)\n",
    "# Other examples:\n",
    "# K = Kernel(17.192,-13.3333,1.18,1.18,8.3,10.7)\n",
    "# K = Kernel(21.085,-19.733,0.739,0.935,10.3,8.7)\n",
    "# K = Kernel(20.267,-2.133,1.817,5.835,0,0)\n",
    "\n",
    "# Then we can see the summary of the Kernel using the method .summary()\n",
    "K.summary()\n",
    "# As explained in the paper, the FFT graph and the intergrated values are key factors which define the Turing patterns.\n",
    "\n",
    "# Now we can construct our model by setting our domain and passing it with the Kernel to Kernel_Turing_model.\n",
    "x = np.linspace(-100,100,201)\n",
    "X, Y = np.meshgrid(x, x)\n",
    "model = Kernel_Turing_model(K,X,Y,1.0)\n",
    "\n",
    "# Then we use the update_grid() method to update the grid a several times: the number of iterations doesn't have to be too big\n",
    "for i in range(10):\n",
    "  print(i)\n",
    "  model.update_grid()\n",
    "\n",
    "# Finally we observe our Turing pattern\n",
    "fix, ax = plt.subplots()\n",
    "model.gridplot(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0)\n",
      "(0, 1)\n",
      "(0, 2)\n",
      "(0, 3)\n",
      "(0, 4)\n",
      "(0, 5)\n",
      "(0, 6)\n",
      "(0, 7)\n",
      "(0, 8)\n",
      "(0, 9)\n",
      "(1, 0)\n",
      "(1, 1)\n",
      "(1, 2)\n",
      "(1, 3)\n",
      "(1, 4)\n",
      "(1, 5)\n",
      "(1, 6)\n",
      "(1, 7)\n",
      "(1, 8)\n",
      "(1, 9)\n",
      "(2, 0)\n",
      "(2, 1)\n",
      "(2, 2)\n",
      "(2, 3)\n",
      "(2, 4)\n",
      "(2, 5)\n",
      "(2, 6)\n",
      "(2, 7)\n",
      "(2, 8)\n",
      "(2, 9)\n"
     ]
    }
   ],
   "source": [
    "# Code used for the graphics in report\n",
    "\n",
    "fig, ax = plt.subplots(1,3,figsize=(15,5))\n",
    "ampAs = [20.267,21.971,25.067]\n",
    "for i in range(3):\n",
    "  K = Kernel(ampAs[i],-2.133,1.817,5.835,0,0)\n",
    "  model = Kernel_Turing_model(K,X,Y,1.0)\n",
    "  for j in range(10):\n",
    "    print((i,j))\n",
    "    model.update_grid()\n",
    "  model.gridplot(ax[i])\n",
    "  ax[i].set_title('Integrated value = {:.3f}'.format(model.Kernel.integral()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teratsujikanademe/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5344: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  pts[1:N+1, 1] = dep1slice\n",
      "/Users/teratsujikanademe/opt/anaconda3/lib/python3.9/site-packages/matplotlib/cbook/__init__.py:1369: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# Here is an example code: First we define our Kernel by passing the amplitude, width, and distance values the two Gaussians\n",
    "# Keep in mind that the order of the arguments is (ampA, ampI, widthA, widthI, distA, distI)\n",
    "K = Kernel(20.267,-3.733,2.601,4.855,0,0)\n",
    "# Other examples:\n",
    "# K = Kernel(17.192,-13.3333,1.18,1.18,8.3,10.7)\n",
    "# K = Kernel(21.085,-19.733,0.739,0.935,10.3,8.7)\n",
    "# K = Kernel(20.267,-2.133,1.817,5.835,0,0)\n",
    "\n",
    "# Then we can see the summary of the Kernel using the method .summary()\n",
    "K.summary()\n",
    "# As explained in the paper, the FFT graph and the intergrated values are key factors which define the Turing patterns.\n",
    "\n",
    "# Now we can construct our model by setting our domain and passing it with the Kernel to Kernel_Turing_model.\n",
    "x = np.linspace(-100,100,201)\n",
    "X, Y = np.meshgrid(x, x)\n",
    "model = Kernel_Turing_model(K,X,Y,1.0)\n",
    "\n",
    "# Then we use the update_grid() method to update the grid a several times: the number of iterations doesn't have to be too big\n",
    "for i in range(10):\n",
    "  print(i)\n",
    "  model.update_grid()\n",
    "\n",
    "# Finally we observe our Turing pattern\n",
    "fix, ax = plt.subplots()\n",
    "model.gridplot(ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/teratsujikanademe/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:5344: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  pts[1:N+1, 1] = dep1slice\n",
      "/Users/teratsujikanademe/opt/anaconda3/lib/python3.9/site-packages/matplotlib/cbook/__init__.py:1369: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return np.asarray(x, float)\n"
     ]
    }
   ],
   "source": [
    "# Here is an example code: First we define our Kernel by passing the amplitude, width, and distance values the two Gaussians\n",
    "# Keep in mind that the order of the arguments is (ampA, ampI, widthA, widthI, distA, distI)\n",
    "K = Kernel(20.267,-2.133,1.817,5.835,0,0)\n",
    "# Other examples:\n",
    "# K = Kernel(17.192,-13.3333,1.18,1.18,8.3,10.7)\n",
    "# K = Kernel(21.085,-19.733,0.739,0.935,10.3,8.7)\n",
    "# K = Kernel(20.267,-2.133,1.817,5.835,0,0)\n",
    "\n",
    "# Then we can see the summary of the Kernel using the method .summary()\n",
    "K.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
